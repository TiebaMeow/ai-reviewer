"""
æ‰¹é‡è®­ç»ƒè„šæœ¬

ä»CSVæ–‡ä»¶è¯»å–è®­ç»ƒæ•°æ®å¹¶æ‰¹é‡æäº¤ç»™AI RevieweræœåŠ¡è¿›è¡Œå¢é‡å­¦ä¹ ã€‚

CSVæ–‡ä»¶æ ¼å¼ï¼š
- text: æ–‡æœ¬å†…å®¹
- task: ä»»åŠ¡åç§°
- label: æ ‡ç­¾

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python batch_train.py --csv data/training_data.csv --url http://localhost:8000
    python batch_train.py --csv data/training_data.csv --batch-size 10 --delay 0.5
"""

import argparse
import csv
import random
import sys
import time
from pathlib import Path

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


class BatchTrainer:
    def __init__(self, base_url: str = "http://localhost:8000", timeout: int = 30):
        """
        åˆå§‹åŒ–æ‰¹é‡è®­ç»ƒå™¨

        Args:
            base_url: AI RevieweræœåŠ¡çš„åŸºç¡€URL
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.base_url = base_url.rstrip("/")
        self.timeout = timeout

        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS", "POST"],
            backoff_factor=1
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)

        self.session = requests.Session()
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def check_server(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å¯ç”¨"""
        try:
            response = self.session.get(f"{self.base_url}/tasks", timeout=self.timeout)
            response.raise_for_status()
            return True
        except Exception as e:
            print(f"âŒ æœåŠ¡å™¨è¿æ¥å¤±è´¥: {e}")
            return False

    def get_available_tasks(self) -> list[str]:
        """è·å–å¯ç”¨ä»»åŠ¡åˆ—è¡¨"""
        try:
            response = self.session.get(f"{self.base_url}/tasks", timeout=self.timeout)
            response.raise_for_status()
            data = response.json()
            return data.get("tasks", [])
        except Exception as e:
            print(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def register_task_if_needed(self, task_name: str, labels: list[str]) -> bool:
        """å¦‚æœä»»åŠ¡ä¸å­˜åœ¨åˆ™æ³¨å†Œä»»åŠ¡"""
        available_tasks = self.get_available_tasks()

        if task_name in available_tasks:
            print(f"âœ“ ä»»åŠ¡ '{task_name}' å·²å­˜åœ¨")
            return True

        # æ³¨å†Œæ–°ä»»åŠ¡
        try:
            payload = {
                "name": task_name,
                "labels": labels
            }
            response = self.session.post(
                f"{self.base_url}/tasks/register",
                json=payload,
                timeout=self.timeout
            )
            response.raise_for_status()
            print(f"âœ“ æˆåŠŸæ³¨å†Œä»»åŠ¡ '{task_name}' æ ‡ç­¾: {labels}")
            return True
        except Exception as e:
            print(f"âŒ æ³¨å†Œä»»åŠ¡ '{task_name}' å¤±è´¥: {e}")
            return False

    def update_task(self, texts: list[str], task: str, labels: list[str]) -> bool:
        """æ›´æ–°ä»»åŠ¡æ¨¡å‹"""
        try:
            payload = {
                "texts": texts,
                "task": task,
                "labels": labels
            }
            response = self.session.post(
                f"{self.base_url}/update",
                json=payload,
                timeout=self.timeout
            )
            response.raise_for_status()
            return True
        except requests.RequestException as e:
            print(f"âŒ æ›´æ–°ä»»åŠ¡ '{task}' å¤±è´¥: {e}")
            if hasattr(e, "response") and e.response is not None:
                if e.response.status_code == 404:
                    print(f"  ä»»åŠ¡ '{task}' ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ³¨å†Œ")
                elif e.response.status_code == 400:
                    print("  æ ‡ç­¾é”™è¯¯æˆ–æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
            return False

    def load_csv_data(self, csv_file: Path) -> list[dict[str, str]]:
        """ä»CSVæ–‡ä»¶åŠ è½½è®­ç»ƒæ•°æ®"""
        data = []

        if not csv_file.exists():
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")

        try:
            with csv_file.open(encoding="utf-8") as f:
                reader = csv.DictReader(f)

                # æ£€æŸ¥å¿…éœ€çš„åˆ—
                required_columns = {"text", "task", "label"}
                fieldnames = reader.fieldnames or []
                if not required_columns.issubset(fieldnames):
                    missing = required_columns - set(fieldnames)
                    raise ValueError(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing}")

                for row_num, row in enumerate(reader, start=2):
                    # éªŒè¯æ•°æ®
                    if not row["text"].strip():
                        print(f"âš ï¸  ç¬¬{row_num}è¡Œ: æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                        continue
                    if not row["task"].strip():
                        print(f"âš ï¸  ç¬¬{row_num}è¡Œ: ä»»åŠ¡åç§°ä¸ºç©ºï¼Œè·³è¿‡")
                        continue
                    if not row["label"].strip():
                        print(f"âš ï¸  ç¬¬{row_num}è¡Œ: æ ‡ç­¾ä¸ºç©ºï¼Œè·³è¿‡")
                        continue

                    data.append({
                        "text": row["text"].strip(),
                        "task": row["task"].strip(),
                        "label": row["label"].strip()
                    })

        except Exception as e:
            raise Exception(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}") from e

        return data

    def group_by_task(self, data: list[dict[str, str]]) -> dict[str, list[dict[str, str]]]:
        """æŒ‰ä»»åŠ¡åˆ†ç»„æ•°æ®"""
        groups = {}
        for item in data:
            task = item["task"]
            if task not in groups:
                groups[task] = []
            groups[task].append(item)
        return groups

    def batch_train(
        self,
        csv_file: Path,
        batch_size: int = 50,
        delay: float = 0.1,
        auto_register: bool = True,
        shuffle: bool = True,
        seed: int | None = None,
        epochs: int = 1,
    ):
        """æ‰¹é‡è®­ç»ƒ"""
        print(f"ğŸ“ åŠ è½½CSVæ–‡ä»¶: {csv_file}")

        # åŠ è½½æ•°æ®
        try:
            data = self.load_csv_data(csv_file)
        except Exception as e:
            print(f"âŒ {e}")
            return False

        if not data:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
            return False

        print(f"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡è®­ç»ƒæ•°æ®")

        # æ£€æŸ¥æœåŠ¡å™¨
        if not self.check_server():
            return False

        # æŒ‰ä»»åŠ¡åˆ†ç»„
        task_groups = self.group_by_task(data)
        print(f"ğŸ“Š å‘ç° {len(task_groups)} ä¸ªä¸åŒçš„ä»»åŠ¡:")

        for task_name, items in task_groups.items():
            # Preserve label order by first occurrence in CSV to ensure deterministic mapping
            seen: set[str] = set()
            labels: list[str] = []
            for item in items:
                lb = item["label"]
                if lb not in seen:
                    seen.add(lb)
                    labels.append(lb)
            print(f"  - {task_name}: {len(items)} æ¡æ•°æ®, æ ‡ç­¾: {labels}")

            # è‡ªåŠ¨æ³¨å†Œä»»åŠ¡
            if auto_register:
                if not self.register_task_if_needed(task_name, labels):
                    print(f"âš ï¸  è·³è¿‡ä»»åŠ¡ '{task_name}' çš„è®­ç»ƒ")
                    continue

        # å®šä¹‰åˆ†å±‚æ‰“ä¹±ä¸äº¤æ›¿æ··åˆï¼ˆæŒ‰æ ‡ç­¾åˆ†æ¡¶å¹¶è½®è¯¢å–æ ·ï¼‰
        def stratified_interleave(items: list[dict[str, str]], rnd: random.Random) -> list[dict[str, str]]:
            buckets: dict[str, list[dict[str, str]]] = {}
            for it in items:
                buckets.setdefault(it["label"], []).append(it)
            # ç‹¬ç«‹æ‰“ä¹±æ¯ä¸ªæ ‡ç­¾æ¡¶
            for arr in buckets.values():
                rnd.shuffle(arr)
            order = list(buckets.keys())
            rnd.shuffle(order)
            mixed: list[dict[str, str]] = []
            # è½®è¯¢å–æ ·ç›´åˆ°æ‰€æœ‰æ¡¶è€—å°½ï¼ˆæ¯è½®ä½¿ç”¨ä¸€æ¬¡æ€§ extendï¼‰
            while any(buckets[k] for k in order):
                round_elems = [buckets[k].pop() for k in order if buckets[k]]
                mixed.extend(round_elems)
            return mixed

        # æ‰¹é‡è®­ç»ƒ
        total_success = 0
        total_failed = 0

        for task_name, items in task_groups.items():
            print(f"\nğŸ”„ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task_name}")
            # è¿›è¡Œå¤šä¸ª epoch çš„åˆ†å±‚æ‰“ä¹±å¹¶åˆ†æ‰¹æäº¤
            for ep in range(epochs):
                rnd = random.Random((seed if seed is not None else random.randrange(1 << 30)) + ep)
                items_epoch = stratified_interleave(items, rnd) if shuffle else list(items)

                for i in range(0, len(items_epoch), batch_size):
                    batch = items_epoch[i:i + batch_size]
                    texts = [item["text"] for item in batch]
                    labels = [item["label"] for item in batch]

                    print(
                        f"  Epoch {ep + 1}/{epochs} æ‰¹æ¬¡ {i // batch_size + 1}: å¤„ç† {len(batch)} æ¡æ•°æ®...",
                        end="",
                    )

                    if self.update_task(texts, task_name, labels):
                        print(" âœ“")
                        total_success += len(batch)
                    else:
                        print(" âŒ")
                        total_failed += len(batch)

                    # å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                    if delay > 0:
                        time.sleep(delay)

        # æ€»ç»“
        print("\nğŸ“ˆ è®­ç»ƒå®Œæˆ!")
        print(f"  âœ“ æˆåŠŸ: {total_success} æ¡")
        print(f"  âŒ å¤±è´¥: {total_failed} æ¡")

        return total_failed == 0


def create_sample_csv(file_path: Path):
    """åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶"""
    sample_data = [
        {"text": "è¿™ç§è§‚ç‚¹ä¼šå¯¼è‡´ç¤¾ä¼šåˆ†è£‚", "task": "æ»‘å¡", "label": "æœ‰"},
        {"text": "æˆ‘è®¤ä¸ºè¿™ä¸ªæ”¿ç­–å¾ˆå¥½", "task": "æ»‘å¡", "label": "æ— "},
        {"text": "ä½ è¿™ç§æƒ³æ³•å°±æ˜¯æƒ³æŒ‘èµ·äº‰ç«¯", "task": "å¼•æˆ˜", "label": "æ˜¯"},
        {"text": "è®©æˆ‘ä»¬ç†æ€§è®¨è®ºè¿™ä¸ªé—®é¢˜", "task": "å¼•æˆ˜", "label": "å¦"},
        {"text": "æŸæŸæ˜æ˜Ÿæ ¹æœ¬ä¸å¦‚å¦ä¸€ä¸ªæ˜æ˜Ÿ", "task": "æ‹‰è¸©", "label": "æ˜¯"},
        {"text": "æˆ‘å–œæ¬¢è¿™ä¸ªæ˜æ˜Ÿçš„ä½œå“", "task": "æ‹‰è¸©", "label": "å¦"},
    ]

    with file_path.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["text", "task", "label"])
        writer.writeheader()
        writer.writerows(sample_data)

    print(f"âœ“ å·²åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶: {file_path}")


def main():
    parser = argparse.ArgumentParser(description="AI Reviewer æ‰¹é‡è®­ç»ƒè„šæœ¬")
    parser.add_argument("--csv", type=str, required=True, help="CSVè®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--url", type=str, default="http://localhost:8000", help="AI RevieweræœåŠ¡URL")
    parser.add_argument("--batch-size", type=int, default=50, help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--delay", type=float, default=0.1, help="æ‰¹æ¬¡é—´å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--timeout", type=int, default=30, help="è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--no-auto-register", action="store_true", help="ä¸è‡ªåŠ¨æ³¨å†Œæ–°ä»»åŠ¡")
    parser.add_argument("--create-sample", action="store_true", help="åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶")
    parser.add_argument("--no-shuffle", action="store_true", help="ä¸æ‰“ä¹±æ ·æœ¬ï¼ˆé»˜è®¤æ‰“ä¹±å¹¶åˆ†å±‚æ··åˆï¼‰")
    parser.add_argument("--seed", type=int, default=None, help="éšæœºç§å­ï¼Œç”¨äºé‡ç°å®éªŒ")
    parser.add_argument("--epochs", type=int, default=1, help="è®­ç»ƒè½®æ•°ï¼ˆå¯¹åŒä¸€CSVé‡å¤å¤šè½®ï¼‰")

    args = parser.parse_args()

    csv_file = Path(args.csv)

    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    if args.create_sample:
        create_sample_csv(csv_file)
        return

    # æ‰§è¡Œæ‰¹é‡è®­ç»ƒ
    trainer = BatchTrainer(base_url=args.url, timeout=args.timeout)

    success = trainer.batch_train(
        csv_file=csv_file,
        batch_size=args.batch_size,
        delay=args.delay,
        auto_register=not args.no_auto_register,
        shuffle=not args.no_shuffle,
        seed=args.seed,
        epochs=args.epochs,
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
